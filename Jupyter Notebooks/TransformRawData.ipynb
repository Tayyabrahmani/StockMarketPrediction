{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ec2c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T19:56:57.771426Z",
     "start_time": "2024-06-15T19:56:56.940610Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de7630",
   "metadata": {},
   "source": [
    "### Get stock name and ticker name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e18312f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T19:56:57.787431Z",
     "start_time": "2024-06-15T19:56:57.772929Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_stock_name(df):\n",
    "    stock_name = df.iloc[0, 0].split(\"|\")[0].strip()\n",
    "    ticker_name = df.iloc[3, 0].split(\".\")[0].strip()\n",
    "    return stock_name, ticker_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676dad32",
   "metadata": {},
   "source": [
    "### Get all the rows containing date and stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9782a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T19:56:58.175679Z",
     "start_time": "2024-06-15T19:56:58.171403Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_time_series_data(df, stock_name):\n",
    "    # Get the index where we find Exchange Date value\n",
    "    date_index = df[df.iloc[:, 0] == 'Exchange Date'].index\n",
    "\n",
    "    # Remove all the rows before exchange date\n",
    "    df = df.iloc[date_index[0]:].reset_index(drop=True)\n",
    "    df = df.iloc[:, 0:10]\n",
    "    \n",
    "    # Make the first row the header\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:].reset_index(drop=True)\n",
    "    \n",
    "    # Convert Exchange Date into date dtype\n",
    "    df['Exchange Date'] = pd.to_datetime(df['Exchange Date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Order the time series to ascending\n",
    "    df = df.iloc[::-1].reset_index(drop=True)\n",
    "    \n",
    "    # Rename column\n",
    "    df = df[['Exchange Date', 'Close', 'Open', 'Low', 'High', 'Volume']]\n",
    "    # df = df.rename(columns={\"Close\": \"Stock Price\"})\n",
    "\n",
    "    # Add stock name\n",
    "    df['Stock Name'] = stock_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b20c78",
   "metadata": {},
   "source": [
    "### Load the data and write the clean data in separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e96317f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T19:56:59.041684Z",
     "start_time": "2024-06-15T19:56:59.036683Z"
    }
   },
   "outputs": [],
   "source": [
    "# def process_excel_file(file_path):\n",
    "#     df = pd.read_excel(file_path, header=None)\n",
    "#     stock_name, ticker_name = get_stock_name(df)\n",
    "#     df_clean = get_time_series_data(df, stock_name)\n",
    "#     output_file_path = os.path.join(\"Output_Data/Processed_Data_Step1\", f\"{stock_name}.csv\")\n",
    "#     df_clean.to_csv(output_file_path, index=False)\n",
    "#     return df\n",
    "\n",
    "# def read_excel_files_from_directory(directory):\n",
    "#     # List all files in the directory\n",
    "#     files = os.listdir(directory)\n",
    "    \n",
    "#     # Filter the list to include only Excel files\n",
    "#     excel_files = [file for file in files if file.endswith('.xls') or file.endswith('.xlsx')]\n",
    "    \n",
    "#     # Create the full file paths\n",
    "#     excel_file_paths = [os.path.join(directory, file) for file in excel_files]\n",
    "    \n",
    "#     # Use multiprocessing Pool to process files in parallel\n",
    "#     with Pool() as pool:\n",
    "#         dataframes = pool.map(process_excel_file, excel_file_paths)\n",
    "    \n",
    "#     return dataframes\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# directory = 'Input_Data'  # Replace with your directory path\n",
    "# all_dataframes = read_excel_files_from_directory(directory)\n",
    "\n",
    "# # Optional: Do something with all_dataframes if needed\n",
    "# print(all_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4232fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T19:57:00.465527Z",
     "start_time": "2024-06-15T19:56:59.396882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Close', 'Volume'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     23\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Input_Data/Raw_Files\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your directory path\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m all_dataframes \u001b[38;5;241m=\u001b[39m read_excel_files_from_directory(directory)\n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mread_excel_files_from_directory\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m stock_name, ticker_name \u001b[38;5;241m=\u001b[39m get_stock_name(df)\n\u001b[1;32m---> 16\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m get_time_series_data(df, stock_name)\n\u001b[0;32m     17\u001b[0m df_clean\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Input_Data/Processed_Files_Step1/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m dataframes\u001b[38;5;241m.\u001b[39mappend(df_clean)\n",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m, in \u001b[0;36mget_time_series_data\u001b[1;34m(df, stock_name)\u001b[0m\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Rename column\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExchange Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# df = df.rename(columns={\"Close\": \"Stock Price\"})\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Add stock name\u001b[39;00m\n\u001b[0;32m     24\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stock_name\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Close', 'Volume'] not in index\""
     ]
    }
   ],
   "source": [
    "def read_excel_files_from_directory(directory):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Filter the list to include only Excel files\n",
    "    excel_files = [file for file in files if file.endswith('.xls') or file.endswith('.xlsx')]\n",
    "    \n",
    "    # Initialize a list to store DataFrames\n",
    "    dataframes = []\n",
    "    \n",
    "    # Read each Excel file into a pandas DataFrame\n",
    "    for file in excel_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_excel(file_path, header=None)\n",
    "        stock_name, ticker_name = get_stock_name(df)\n",
    "        df_clean = get_time_series_data(df, stock_name)\n",
    "        df_clean.to_csv(f\"../Input_Data/Processed_Files_Step1/{stock_name}.csv\",index=False)\n",
    "        dataframes.append(df_clean)\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "# Example usage\n",
    "directory = '../Input_Data/Raw_Files'  # Replace with your directory path\n",
    "all_dataframes = read_excel_files_from_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2abb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:21:40.497288Z",
     "start_time": "2024-06-04T16:21:40.445420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optionally, combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5f939-35de-4f28-950e-8f0ec70514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"../Output_Data/cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea127c-764e-4b4f-84f2-09a924b0f1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
